# Example configuration for running the modular pipeline
# Recommended entry point: python main.py --config your_config.yaml
# This config will be validated for required keys and types.
# If you misspell a key or omit a required field, you will get a clear error message.

pipeline_type: modular    # Use the modular, HPO-enabled pipeline
# For local runs, use local CSV paths.
train_data: datasets/heart_train.csv
validation_data: datasets/heart_val.csv
test_data: datasets/heart_test.csv
target_column: target
preprocessing:
  impute_strategy: [mean, median, knn]
  scaling: [standard, none]
feature_engineering:
  add_polynomial: [True, False]
model:
  n_estimators: [100, 200]
model_name: heart_model
run_name: local_test
output_path: ./results
missingness_threshold: 0.75
categorical_threshold: 15
text_threshold: 100
use_onehot: false  # Set to true to enable one-hot encoding for categorical features
use_tfidf: false   # Set to true to enable TF-IDF vectorization for text features
use_poly: false    # Set to true to enable polynomial features for numeric features
random_seed: 42
autogluon_hyperparameters:
  RF: {}
  # Example: uncomment and customize if needed
  # GBM: {extra_trees: True, ag_args: {name_suffix: 'EXTRA'}}
save_leaderboard: true
save_predictions: true
save_config_copy: true
time_limit: 60  # Reduced for quick testing
presets: good_quality 